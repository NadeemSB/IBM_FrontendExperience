{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoreML3_AC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11mypV_5CF1S_NCXKOjOeB_U3WfeS78ut",
      "authorship_tag": "ABX9TyMB9BM2mJf6ygto2dL4gMSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadeemSB/IBM_FrontendExperience/blob/main/CoreML3_AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install tensorflow==1.14\n",
        "!python -m pip install keras==2.2.4\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from keras.callbacks import Callback, ModelCheckpoint"
      ],
      "metadata": {
        "id": "LYlDwVFNGeQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybv1rN0LvVCE"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH, IMG_HEIGHT = 150, 150\n",
        "TRAIN_DATA_DIR = '/content/drive/MyDrive/CoreML_AC/train'\n",
        "VALIDATION_DATA_DIR = '/content/drive/MyDrive/CoreML_AC/valid'\n",
        "NB_TRAIN_SAMPLES = 800\n",
        "NB_VALIDATION_SAMPLES = 140\n",
        "NB_EPOCH = 10\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(IMG_WIDTH, IMG_HEIGHT,3))\n",
        "x = Convolution2D(32, 3, 3)(input)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Convolution2D(64, 3, 3)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Convolution2D(128, 3, 3)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Convolution2D(128, 3, 3, activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=input, outputs=x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAIN_DATA_DIR,\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        VALIDATION_DATA_DIR,\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=NB_TRAIN_SAMPLES // 32,\n",
        "    epochs=NB_EPOCH,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=NB_VALIDATION_SAMPLES // 32)\n",
        "\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "CW8T15WvkZ2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdabdf4-214d-4901-cdfd-9f4d4884532b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 85 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 42s 2s/step - loss: 1.0129 - acc: 0.6313 - val_loss: 0.4547 - val_acc: 0.7500\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.5054 - acc: 0.7607 - val_loss: 0.4438 - val_acc: 0.8125\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 39s 2s/step - loss: 0.3929 - acc: 0.8416 - val_loss: 0.4302 - val_acc: 0.8125\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.3394 - acc: 0.8555 - val_loss: 0.4440 - val_acc: 0.8125\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 38s 2s/step - loss: 0.2010 - acc: 0.9234 - val_loss: 0.7088 - val_acc: 0.8125\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.2147 - acc: 0.9195 - val_loss: 0.7213 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.2110 - acc: 0.9215 - val_loss: 0.7287 - val_acc: 0.7500\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.2174 - acc: 0.9542 - val_loss: 0.4045 - val_acc: 0.8125\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.1702 - acc: 0.9403 - val_loss: 0.2705 - val_acc: 0.9375\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 38s 2s/step - loss: 0.0491 - acc: 0.9812 - val_loss: 0.7711 - val_acc: 0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall h5py\n",
        "!pip install h5py==2.10.0"
      ],
      "metadata": {
        "id": "irq5_QUR_LGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "70a3661f-72ba-41bc-d738-85ab860dff4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: h5py 3.1.0\n",
            "Uninstalling h5py-3.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py-3.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libaec-9c9e97eb.so.0.0.10\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5-00e8fae8.so.200.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5_hl-383c339f.so.200.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libsz-e7aa62f5.so.2.0.1\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libz-eb09ad1d.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled h5py-3.1.0\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# dimensions of our images\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "# load the model we saved\n",
        "model = load_model('/content/model.h5')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "mypath = \"/content/drive/MyDrive/CoreML_AC/apredict\"\n",
        "\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(onlyfiles)\n",
        "# predicting images\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(\"/content/drive/MyDrive/CoreML_AC/apredict/\"+file, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "    result = model.predict(x)\n",
        "    print(\"predict result..\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7JWhJcMNvWd",
        "outputId": "7ea6e97b-4a21-4ffa-830f-ad1aabcb0f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2.jpg', '3.jpg', '4.jpg']\n",
            "predict result..\n",
            "[[1. 0.]]\n",
            "predict result..\n",
            "[[1. 0.]]\n",
            "predict result..\n",
            "[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COREML Conversion**"
      ],
      "metadata": {
        "id": "IzoMaWe9-Xph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coremltools==3.0b6"
      ],
      "metadata": {
        "id": "F2kXBC3jqp8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd6899-63cb-42ff-b9ef-90d56b5c9de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coremltools==3.0b6\n",
            "  Downloading coremltools-3.0b6-cp37-none-manylinux1_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 16.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools==3.0b6) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==3.0b6) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==3.0b6) (1.15.0)\n",
            "Installing collected packages: coremltools\n",
            "Successfully installed coremltools-3.0b6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools\n",
        "output_labels = ['Damaged', 'Undamaged']\n",
        "coreml_model = coremltools.converters.keras.convert('model.h5', input_names=['image'], output_names=['output'],\n",
        "                                                   class_labels=output_labels,\n",
        "                                                   image_input_names='image')\n",
        "\n",
        "coreml_model.author = 'IBM'\n",
        "coreml_model.short_description = 'Dent Detection Classifier converted from a Keras model'\n",
        "coreml_model.input_description['image'] = 'Takes as input an image'\n",
        "coreml_model.output_description['output'] = 'Prediction as Damaged or Undamaged'\n",
        "coreml_model.output_description['classLabel'] = 'Returns Damaged or Undamaged as class label'"
      ],
      "metadata": {
        "id": "wX33orLFq77K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06273fdb-07d9-42dd-91f1-d4d4b2fc0505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TensorFlow version 1.14.0 detected. Last version known to be fully compatible is 1.13.1 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : input_1, <keras.engine.input_layer.InputLayer object at 0x7fab15e8c650>\n",
            "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x7fab15e8ca50>\n",
            "2 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x7fab15e8c890>\n",
            "3 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x7fab15e8c9d0>\n",
            "4 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x7fab15e8cc90>\n",
            "5 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x7fab15e8ce10>\n",
            "6 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x7fab15e8ce90>\n",
            "7 : conv2d_4, <keras.layers.convolutional.Conv2D object at 0x7fab15e930d0>\n",
            "8 : conv2d_4__activation__, <keras.layers.core.Activation object at 0x7fab15d0d950>\n",
            "9 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x7fab15e931d0>\n",
            "10 : flatten_1, <keras.layers.core.Flatten object at 0x7fab15e933d0>\n",
            "11 : dense_1, <keras.layers.core.Dense object at 0x7fab15e93410>\n",
            "12 : dense_1__activation__, <keras.layers.core.Activation object at 0x7fab15d21610>\n",
            "13 : dense_2, <keras.layers.core.Dense object at 0x7fab15e936d0>\n",
            "14 : dense_2__activation__, <keras.layers.core.Activation object at 0x7fab1f115190>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coreml_model.save('DentDetection.mlmodel')"
      ],
      "metadata": {
        "id": "BXRYBiI9rV5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coreml_model_path = \"/content/DentDetection.mlmodel\"\n",
        "spec = coremltools.utils.load_spec(coreml_model_path)\n",
        "builder = coremltools.models.neural_network.NeuralNetworkBuilder(spec=spec)\n",
        "builder.inspect_layers(last=3)\n",
        "builder.inspect_input_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH1m_PZUrafU",
        "outputId": "b64d5b80-2e78-4a46-83ec-6292ae4b31d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Id: 13], Name: dense_2__activation__ (Type: softmax)\n",
            "          Updatable: False\n",
            "          Input blobs: ['dense_2_output']\n",
            "          Output blobs: ['output']\n",
            "[Id: 12], Name: dense_2 (Type: innerProduct)\n",
            "          Updatable: False\n",
            "          Input blobs: ['dense_1__activation___output']\n",
            "          Output blobs: ['dense_2_output']\n",
            "[Id: 11], Name: dense_1__activation__ (Type: activation)\n",
            "          Updatable: False\n",
            "          Input blobs: ['dense_1_output']\n",
            "          Output blobs: ['dense_1__activation___output']\n",
            "[Id: 0] Name: image\n",
            "          Type: imageType {\n",
            "  width: 150\n",
            "  height: 150\n",
            "  colorSpace: RGB\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuralnetwork_spec = builder.spec\n",
        "neuralnetwork_spec.description.input[0].type.imageType.width = 150\n",
        "neuralnetwork_spec.description.input[0].type.imageType.height = 150\n",
        "\n",
        "\"\"\"from coremltools.proto import FeatureTypes_pb2 as _FeatureTypes_pb2\n",
        "grayscale = _FeatureTypes_pb2.ImageFeatureType.ColorSpace.Value('GRAYSCALE')\n",
        "neuralnetwork_spec.description.input[0].type.imageType.colorSpace = grayscale\"\"\"\n",
        "\n",
        "# let's inspect the input again to confirm the change in input type\n",
        "builder.inspect_input_features()"
      ],
      "metadata": {
        "id": "toe82fgLrj4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38276395-41ca-4847-e7dc-f1fa36c2ba1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Id: 0] Name: image\n",
            "          Type: imageType {\n",
            "  width: 150\n",
            "  height: 150\n",
            "  colorSpace: RGB\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_spec = builder.spec\n",
        "builder.make_updatable(['dense_1', 'dense_2'])"
      ],
      "metadata": {
        "id": "A7MDCYYQrsHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder.set_categorical_cross_entropy_loss(name='lossLayer', input= 'output')\n",
        "\n",
        "from coremltools.models.neural_network import SgdParams\n",
        "builder.set_sgd_optimizer(SgdParams(lr=0.01, batch=5))\n",
        "builder.set_epochs(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ScIaLf1Jz-",
        "outputId": "6db4d93e-f5ee-4ae7-da18-46e1e5b4bd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now adding input output_true as target for categorical cross-entropy loss layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_spec.isUpdatable = True\n",
        "model_spec.specificationVersion = coremltools._MINIMUM_UPDATABLE_SPEC_VERSION\n",
        "\n",
        "model_spec.description.trainingInput[0].shortDescription = 'Image for training and updating the model'\n",
        "model_spec.description.trainingInput[1].shortDescription = 'Set the value as damaged or undamaged and update the model'"
      ],
      "metadata": {
        "id": "h11xYccDsjwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version History\n",
        "\n",
        "\n",
        "*   V1 : \n",
        "*   V2 : \n",
        "*   V3 :\n",
        "*   V4 : Exchanging the Output labels\n",
        "*   V5 : Added images to dataset for application setup\n",
        "*   V6 : Aircraft Dataset\n",
        "*   V7 : Aircraft Dataset with new version images 46 and 47\n",
        "*   V8 : Aircraft Dataset with refined new model"
      ],
      "metadata": {
        "id": "5qu0JoI2hGOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coremltools.utils.save_spec(model_spec, 'DentDetectionUpdatable(V_8).mlmodel')"
      ],
      "metadata": {
        "id": "j0gd6my7syRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder.inspect_loss_layers()"
      ],
      "metadata": {
        "id": "iBSdp79DuQpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8850d178-019f-43a3-a76b-b821932cd3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Id: 0], Name: lossLayer (Type: categoricalCrossEntropyLossLayer)\n",
            "          Loss Input: output\n",
            "          Loss Target: output_true\n"
          ]
        }
      ]
    }
  ]
}